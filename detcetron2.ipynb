{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMlga5DvWypPNEbPO+bnwtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaimahaffar/PLANT-DISEASE-DETECTION/blob/main/detcetron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "install Detectron2"
      ],
      "metadata": {
        "id": "8IBHDoOKgjjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9XZAunXdNTa"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2  # Importe la bibliothèque Detectron2, utilisée pour les tâches de vision par ordinateur comme la détection d'objets, la segmentation, etc.\n",
        "from detectron2.utils.logger import setup_logger  # Importe la fonction pour configurer le système de journalisation (logging) de Detectron2.\n",
        "setup_logger()  # Configure le logger pour afficher les messages d'erreur et les informations d'exécution de Detectron2.\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np  # Importe NumPy, une bibliothèque pour les opérations mathématiques, manipulation de matrices et calcul scientifique.\n",
        "import os, json, cv2, random\n",
        "\n",
        "from google.colab.patches import cv2_imshow  # Importe une fonction spécifique à Google Colab pour afficher des images avec OpenCV directement dans l'interface Colab.\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo  # Importe un module de Detectron2 qui permet d'accéder à des modèles pré-entraînés disponibles en ligne.\n",
        "from detectron2.engine import DefaultPredictor  # Importe une classe permettant de créer un prédicteur par défaut qui exécute un modèle entraîné pour des prédictions.\n",
        "from detectron2.config import get_cfg  # Importe une fonction pour obtenir un objet de configuration (cfg) permettant de configurer et personnaliser les modèles et autres paramètres.\n",
        "from detectron2.utils.visualizer import Visualizer  # Importe une classe utilisée pour visualiser les résultats, comme les boîtes englobantes et les segments d'image prédits par un modèle.\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog  # Importe des outils pour gérer les métadonnées et les ensembles de données dans Detectron2. Ils permettent d'enregistrer, charger, et utiliser des ensembles de données spécifiques.\n"
      ],
      "metadata": {
        "id": "iyC1QhyKdYnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im=cv2.imread('/content/unnamed.jpg')\n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "2pfCxZA4lBQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "# fonction obtient un objet de configuration par défaut pour Detectron2.(contient les hyperparametre,type de modéle,les poids..)\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "#charger un modèle de segmentation d'instance (Instance Segmentation) basé sur Mask R-CNN\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Il correspond à la probabilité minimale qu'une détection soit considérée comme valide.\n",
        "# Find a model from detectron2's model zoo.  https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")#définit les poids pré-entraînés du modèle.\n",
        "cfg.MODEL.DEVICE = \"cpu\"  # Forces the model to run on the CPU instead of trying to use a GPU\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ],
      "metadata": {
        "id": "Nl2_rix7m7Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the outputs - tensors and bounding boxes.\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ],
      "metadata": {
        "id": "F1ymRYv9nYnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.8)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "Sa0siboUowyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on a custom dataset"
      ],
      "metadata": {
        "id": "pNIeyFwLtDKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dzZr0zSfH3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_trainv2\", {}, \"/content/drive/MyDrive/data_leaves/train/_annotations.coco.json\", \"/content/drive/MyDrive/data_leaves/train\")\n",
        "register_coco_instances(\"my_dataset_valv2\", {}, \"/content/drive/MyDrive/data_leaves/valid/_annotations.coco.json\", \"/content/drive/MyDrive/data_leaves/valid\")\n",
        "register_coco_instances(\"my_dataset_testv2\", {}, \"/content/drive/MyDrive/data_leaves/test/_annotations.coco.json\", \"/content/drive/MyDrive/data_leaves/test\")"
      ],
      "metadata": {
        "id": "WSmMPvSSo5cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_metadata = MetadataCatalog.get(\"my_dataset_trainv2\")\n",
        "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_trainv2\")\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_testv2\")"
      ],
      "metadata": {
        "id": "JP56diDsxjsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metadata = MetadataCatalog.get(\"my_dataset_valv2\")\n",
        "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_valv2\")\n",
        "test_metadata_dicts=DatasetCatalog.get(\"my_dataset_testv2\")"
      ],
      "metadata": {
        "id": "hvnharU2yfds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##check and fix dataset annotation"
      ],
      "metadata": {
        "id": "MU_LjPnLCU0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "from detectron2.data import DatasetCatalog\n",
        "\n",
        "# Load your dataset\n",
        "dataset_dicts = DatasetCatalog.get(\"my_dataset_trainv2\")\n",
        "\n",
        "# Get the unique class IDs from annotations\n",
        "class_ids = set()\n",
        "\n",
        "for d in dataset_dicts:\n",
        "    for annotation in d['annotations']:\n",
        "        class_ids.add(annotation['category_id'])\n",
        "\n",
        "print(f\"Number of unique classes in dataset: {len(class_ids)}\")\n",
        "print(f\"Class IDs: {class_ids}\")"
      ],
      "metadata": {
        "id": "taU9uDEyCUjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fix\n",
        "#import json\n",
        "\n",
        "#def fix_category_ids(annotation_file, output_file):\n",
        "    # Load the annotation file\n",
        "#    with open(annotation_file, 'r') as f:\n",
        "#        data = json.load(f)\n",
        "\n",
        "    # Define the mapping: old IDs -> new IDs\n",
        "#    id_mapping = {1: 1, 2: 2, 3: 3, 4: 4, 6: 5, 7: 6, 8: 7}\n",
        "\n",
        "    # Update category IDs in the annotations\n",
        "#    for annotation in data['annotations']:\n",
        "#        annotation['category_id'] = id_mapping[annotation['category_id']]\n",
        "\n",
        "    # Update the categories section if necessary\n",
        "#    for category in data['categories']:\n",
        "#        category['id'] = id_mapping[category['id']]\n",
        "\n",
        "    # Save the modified annotation file\n",
        "#    with open(output_file, 'w') as f:\n",
        "#        json.dump(data, f)\n",
        "\n",
        "# Fix train, validation, and test datasets\n",
        "#fix_category_ids('/content/drive/MyDrive/extracted_data/valid/_annotations.coco.json', '/content/drive/MyDrive/extracted_data/valid/_annotations_fixed.coco.json')\n",
        "#fix_category_ids('/content/drive/MyDrive/extracted_data/train/_annotations.coco.json', '/content/drive/MyDrive/extracted_data/train/_annotations_fixed.coco.json')\n",
        "#fix_category_ids('/content/drive/MyDrive/extracted_data/test/_annotations.coco.json', '/content/drive/MyDrive/extracted_data/test/_annotations_fixed.coco.json')\n"
      ],
      "metadata": {
        "id": "IOcZ97BMCgbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "_5EWWUZ90APc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some random samples\n",
        "for d in random.sample(train_dataset_dicts, 4):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yWy6haXW0hx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "59UjMOsy10wV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gbFDtBGD-Ewu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer # default training loop for object detection models,\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/ColabNotebooks/models_optimized/Detectron2_Models1\"\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_trainv2\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_testv2\")\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "#(The model will start training from these pre-trained weights rather than from scratch, which can help it converge faster)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "#defines how many images will be processed in each batch during training\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR(This is a key parameter for controlling how much to adjust the model's weights\n",
        "#during each optimization step. A smaller learning rate makes the model learn slowly,\n",
        "#while a larger one makes it learn faster but with more risk of instability.)\n",
        "cfg.SOLVER.MAX_ITER = 200    # 1000 iterations seems good enough for this dataset/ controls how long the model trains.\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7  # We have 7 classes.\n",
        "# NOTE: this config means the number of classes, without the background. Do not use num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "cfg.MODEL.DEVICE = \"cpu\"  # Forces the model to run on the CPU instead of trying to use a GPU\n",
        "trainer = DefaultTrainer(cfg) #Create an instance of of DefaultTrainer with the given congiguration\n",
        "trainer.resume_or_load(resume=False) #Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8wf4VfXe0xor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "fyQBiHHVBHln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference & evaluation using the trained model"
      ],
      "metadata": {
        "id": "HhjQNsa99_hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/content/drive/MyDrive/ColabNotebooks/models_optimized/Detectron2_Models1/model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "IhgHzl-zZmCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify segmentation on random validation images"
      ],
      "metadata": {
        "id": "l76Bj6bsCyaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(val_dataset_dicts, 2):    #select number of images for display\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "               metadata=val_metadata,\n",
        "               scale=0.5,\n",
        "               instance_mode=ColorMode.IMAGE)  # use full color mode instead of IMAGE_BW\n",
        "  # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "iaru5jtiB6iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check average precision and recall. (Need more validation data than just 2 images with handful of annotations)"
      ],
      "metadata": {
        "id": "7_q5l9hSWlul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"my_dataset_valv2\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_valv2\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "metadata": {
        "id": "5Q314OxfDCWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_im = cv2.imread(\"/content/images (1).jpg\")\n",
        "outputs  = predictor(new_im)\n",
        "\n",
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "oXUo1voTWohf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "\n",
        "# Set a threshold margin for bounding box edges\n",
        "threshold_margin = 10  # Adjust as needed\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(\n",
        "    cfg.OUTPUT_DIR,\n",
        "    \"/content/drive/MyDrive/ColabNotebooks/models_optimized/Detectron2_Models1/model_final.pth\"\n",
        ")  # Path to the trained model\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "for d in random.sample(val_dataset_dicts, 2):  # Select number of images for display\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    # Filter out bounding boxes that are too close to the image edges\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    boxes = instances.pred_boxes.tensor.numpy()\n",
        "    height, width, _ = im.shape\n",
        "    filtered_boxes = []\n",
        "    keep_indices = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = box\n",
        "        if (x1 > threshold_margin and y1 > threshold_margin and\n",
        "            x2 < width - threshold_margin and y2 < height - threshold_margin):\n",
        "            filtered_boxes.append(box)\n",
        "            keep_indices.append(i)\n",
        "\n",
        "    # Keep only filtered instances\n",
        "    if keep_indices:\n",
        "        instances = instances[keep_indices]\n",
        "\n",
        "    # Customize the Visualizer to display only class names\n",
        "    v = Visualizer(\n",
        "        im[:, :, ::-1],\n",
        "        metadata=val_metadata,\n",
        "        scale=0.5,\n",
        "        instance_mode=ColorMode.IMAGE\n",
        "    )\n",
        "\n",
        "    # Draw only class names, exclude confidence scores\n",
        "    labels = [\n",
        "        f\"{val_metadata.thing_classes[class_id]}\"\n",
        "        for class_id in instances.pred_classes\n",
        "    ]\n",
        "\n",
        "    out = v.overlay_instances(\n",
        "        boxes=instances.pred_boxes if instances.has(\"pred_boxes\") else None,\n",
        "        masks=None,\n",
        "        keypoints=None,\n",
        "        labels=labels,  # Display only class names\n",
        "        assigned_colors=None  # Use default colors\n",
        "    )\n",
        "\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "7ZvqnsDhaE1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "\n",
        "# Set a threshold margin for bounding box edges\n",
        "threshold_margin = 10  # Adjust as needed\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(\n",
        "    cfg.OUTPUT_DIR,\n",
        "    \"/content/drive/MyDrive/ColabNotebooks/models_optimized/Detectron2_Models1/model_final.pth\"\n",
        ")  # Path to the trained model\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3  # Set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "for d in random.sample(val_dataset_dicts, 5):  # Select number of images for display\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    # Filter out bounding boxes that are too close to the image edges\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    boxes = instances.pred_boxes.tensor.numpy()\n",
        "    height, width, _ = im.shape\n",
        "    filtered_boxes = []\n",
        "    keep_indices = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = box\n",
        "        if (x1 > threshold_margin and y1 > threshold_margin and\n",
        "            x2 < width - threshold_margin and y2 < height - threshold_margin):\n",
        "            filtered_boxes.append(box)\n",
        "            keep_indices.append(i)\n",
        "\n",
        "    # Keep only filtered instances\n",
        "    if keep_indices:\n",
        "        instances = instances[keep_indices]\n",
        "\n",
        "    # Customize the Visualizer to display only class names\n",
        "    v = Visualizer(\n",
        "        im[:, :, ::-1],\n",
        "        metadata=val_metadata,\n",
        "        scale=0.5,\n",
        "        instance_mode=ColorMode.IMAGE\n",
        "    )\n",
        "\n",
        "    # Draw only class names, include masks\n",
        "    labels = [\n",
        "        f\"{val_metadata.thing_classes[class_id]}\"\n",
        "        for class_id in instances.pred_classes\n",
        "    ]\n",
        "\n",
        "    out = v.overlay_instances(\n",
        "        boxes=instances.pred_boxes if instances.has(\"pred_boxes\") else None,\n",
        "        masks=instances.pred_masks if instances.has(\"pred_masks\") else None,  # Keep masks\n",
        "        keypoints=None,\n",
        "        labels=labels,  # Display only class names\n",
        "        assigned_colors=None  # Use default colors\n",
        "    )\n",
        "\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "2Ow9T69cxJ0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSsAVTHxzVkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}